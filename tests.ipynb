{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "# converting jupyter notebook file to script\n",
    "!jupyter nbconvert --to script module_notebook.ipynb\n",
    "import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_parameters = main.initialize_parameters\n",
    "forward_propagation = main.forward_propagation\n",
    "backward_propagation = main.backward_propagation\n",
    "update_parameters = main.update_parameters\n",
    "compute_loss = main.compute_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikolajekiert/CNN-Brain-Tumor-Detection/main.py:123: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  Z[i, h, w, c] = np.sum(a_slice_prev * W[:, :, :, c]) + float(b[:, :, :, c])\n"
     ]
    }
   ],
   "source": [
    "class TestModel(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.parameters = initialize_parameters()\n",
    "        self.X_train = np.random.randn(10, 128, 128, 1)  \n",
    "        self.Y_train = np.random.randint(0, 2, (10, 1))  \n",
    "        self.X_test = np.random.randn(5, 128, 128, 1)    \n",
    "        self.Y_test = np.random.randint(0, 2, (5, 1))    \n",
    "        self.num_epochs = 10\n",
    "        self.learning_rate = 0.01\n",
    "\n",
    "    def test_initialize_parameters(self):\n",
    "        parameters = initialize_parameters()\n",
    "        self.assertEqual(parameters[\"W1\"].shape, (3, 3, 1, 32))\n",
    "        self.assertEqual(parameters[\"b1\"].shape, (1, 1, 1, 32))\n",
    "        self.assertEqual(parameters[\"W2\"].shape, (3, 3, 32, 64))\n",
    "        self.assertEqual(parameters[\"b2\"].shape, (1, 1, 1, 64))\n",
    "        self.assertEqual(parameters[\"W3\"].shape, (128, 64 * 6 * 6))\n",
    "        self.assertEqual(parameters[\"b3\"].shape, (128, 1))\n",
    "        self.assertEqual(parameters[\"W4\"].shape, (1, 128))\n",
    "        self.assertEqual(parameters[\"b4\"].shape, (1, 1))\n",
    "\n",
    "    def test_forward_propagation(self):\n",
    "        A4, cache = forward_propagation(self.X_train, self.parameters)\n",
    "        self.assertEqual(A4.shape, (1, self.X_train.shape[0]))\n",
    "\n",
    "    def test_backward_propagation(self):\n",
    "        A4, cache = forward_propagation(self.X_train, self.parameters)\n",
    "        grads = backward_propagation(self.X_train, self.Y_train, self.parameters, cache)\n",
    "        self.assertEqual(grads[\"dW1\"].shape, self.parameters[\"W1\"].shape)\n",
    "        self.assertEqual(grads[\"db1\"].shape, self.parameters[\"b1\"].shape)\n",
    "        self.assertEqual(grads[\"dW2\"].shape, self.parameters[\"W2\"].shape)\n",
    "        self.assertEqual(grads[\"db2\"].shape, self.parameters[\"b2\"].shape)\n",
    "        self.assertEqual(grads[\"dW3\"].shape, self.parameters[\"W3\"].shape)\n",
    "        self.assertEqual(grads[\"db3\"].shape, self.parameters[\"b3\"].shape)\n",
    "        self.assertEqual(grads[\"dW4\"].shape, self.parameters[\"W4\"].shape)\n",
    "        self.assertEqual(grads[\"db4\"].shape, self.parameters[\"b4\"].shape)\n",
    "\n",
    "    def test_update_parameters(self):\n",
    "        A4, cache = forward_propagation(self.X_train, self.parameters)\n",
    "        grads = backward_propagation(self.X_train, self.Y_train, self.parameters, cache)\n",
    "        updated_parameters = update_parameters(self.parameters, grads, self.learning_rate)\n",
    "        self.assertEqual(updated_parameters[\"W1\"].shape, self.parameters[\"W1\"].shape)\n",
    "        self.assertEqual(updated_parameters[\"b1\"].shape, self.parameters[\"b1\"].shape)\n",
    "        self.assertEqual(updated_parameters[\"W2\"].shape, self.parameters[\"W2\"].shape)\n",
    "        self.assertEqual(updated_parameters[\"b2\"].shape, self.parameters[\"b2\"].shape)\n",
    "        self.assertEqual(updated_parameters[\"W3\"].shape, self.parameters[\"W3\"].shape)\n",
    "        self.assertEqual(updated_parameters[\"b3\"].shape, self.parameters[\"b3\"].shape)\n",
    "        self.assertEqual(updated_parameters[\"W4\"].shape, self.parameters[\"W4\"].shape)\n",
    "        self.assertEqual(updated_parameters[\"b4\"].shape, self.parameters[\"b4\"].shape)\n",
    "\n",
    "    def test_compute_loss(self):\n",
    "        A4, _ = forward_propagation(self.X_train, self.parameters)\n",
    "        cost = compute_loss(A4, self.Y_train)\n",
    "        self.assertIsInstance(cost, float)\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=[''], exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
